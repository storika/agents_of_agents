"""
CMO (Chief Marketing Orchestrator) Agent - ADK Implementation with Weave Integration
"""

import json
import os
from typing import List, Dict, Any
from dotenv import load_dotenv
import weave

# Load environment variables
load_dotenv()

# Initialize Weave
WANDB_API_KEY = os.getenv("WANDB_API_KEY", "3875d64c87801e9a71318a5a8754a0ee2d556946")
os.environ['WANDB_API_KEY'] = WANDB_API_KEY

weave.init("mason-choi-storika/WeaveHacks2")
print("[INFO] ğŸ Weave initialized for CMO Agent: mason-choi-storika/WeaveHacks2")

# Now import ADK
from google.adk.agents.llm_agent import Agent

# Import CMO tools
from cmo_agent.tools import (
    research_trends,
    generate_content_candidate,
    evaluate_content,
    x_publish,
    get_last_iteration_metrics,
    save_iteration_metrics
)

# Import sub-agent management
from cmo_agent.sub_agents import (
    SubAgentTeam,
    # Sequential layer agents
    call_research_layer,
    call_creative_writer_layer,
    call_generator_layer,
    call_critic_layer,
    call_safety_layer
)


# ===== GLOBAL SUB-AGENT TEAM =====
# CMOì˜ ì„œë¸Œ ì—ì´ì „íŠ¸ íŒ€ (ì „ì—­ìœ¼ë¡œ ìœ ì§€)
_global_sub_agent_team: SubAgentTeam = None


@weave.op()
def initialize_sub_agents(hire_plan: List[Dict[str, Any]]) -> str:
    """
    HR Agentì˜ hire_planì„ ê¸°ë°˜ìœ¼ë¡œ ì„œë¸Œ ì—ì´ì „íŠ¸ íŒ€ ì´ˆê¸°í™”
    
    Args:
        hire_plan: HR Agentê°€ ìƒì„±í•œ ê³ ìš© ê³„íš
    
    Returns:
        ì´ˆê¸°í™” ìƒíƒœ ë©”ì‹œì§€
    """
    global _global_sub_agent_team
    
    print("\n" + "="*70)
    print("ğŸ¤– ì„œë¸Œ ì—ì´ì „íŠ¸ íŒ€ ì´ˆê¸°í™”")
    print("="*70 + "\n")
    
    try:
        _global_sub_agent_team = SubAgentTeam()
        _global_sub_agent_team.apply_hire_plan(hire_plan)
        
        agents_list = _global_sub_agent_team.list_agents()
        
        result = {
            "status": "success",
            "team_size": len(agents_list),
            "agents": agents_list,
            "message": f"âœ… {len(agents_list)}ëª…ì˜ ì„œë¸Œ ì—ì´ì „íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
        return json.dumps(result, indent=2, ensure_ascii=False)
    
    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"ì„œë¸Œ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
        }, indent=2, ensure_ascii=False)


@weave.op()
def get_sub_agent_team() -> SubAgentTeam:
    """ì„œë¸Œ ì—ì´ì „íŠ¸ íŒ€ ê°€ì ¸ì˜¤ê¸°"""
    global _global_sub_agent_team
    
    if _global_sub_agent_team is None:
        # ê¸°ë³¸ íŒ€ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
        _global_sub_agent_team = SubAgentTeam()
    
    return _global_sub_agent_team


# ===== CMO ORCHESTRATION FUNCTION =====

@weave.op()
def orchestrate_content_creation(
    iteration: int = 0,
    topic: str = "AI agents",
    num_candidates: int = 3
) -> str:
    """
    ì½˜í…ì¸  ìƒì„± ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ)
    
    Args:
        iteration: í˜„ì¬ ë°˜ë³µ íšŸìˆ˜
        topic: ì½˜í…ì¸  ì£¼ì œ
        num_candidates: ìƒì„±í•  í›„ë³´ ìˆ˜ (3-6 ê¶Œì¥)
    
    Returns:
        JSON í˜•ì‹ì˜ CMO ì‹¤í–‰ ê²°ê³¼
    """
    try:
        print(f"\n{'='*70}")
        print(f"ğŸ¯ CMO Iteration {iteration}: {topic}")
        print(f"{'='*70}\n")
        
        # === 1ï¸âƒ£ RESEARCH STAGE ===
        print("1ï¸âƒ£ Research Stage - íŠ¸ë Œë“œ ì¡°ì‚¬ ì¤‘...")
        research_result = json.loads(research_trends(topic=topic))
        print(f"   âœ“ ë°œê²¬ëœ í† í”½: {len(research_result['topics'])}ê°œ")
        print(f"   âœ“ í‚¤ì›Œë“œ: {', '.join(research_result['keywords'][:5])}")
        
        # === 2ï¸âƒ£ GENERATE STAGE ===
        print(f"\n2ï¸âƒ£ Generate Stage - {num_candidates}ê°œ í›„ë³´ ìƒì„± ì¤‘...")
        candidates = []
        
        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (use_sub_agentsëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
        for i in range(num_candidates):
            # ê° í† í”½ì—ì„œ í›„ë³´ ìƒì„±
            selected_topic = research_result['topics'][i % len(research_result['topics'])]
            candidate_json = generate_content_candidate(
                topic=selected_topic,
                tone=research_result['tone_style']
            )
            candidate_dict = json.loads(candidate_json)
            candidates.append(candidate_dict)
            print(f"   âœ“ í›„ë³´ {i+1}: {candidate_dict['text'][:60]}...")
        
        # === 3ï¸âƒ£ EVALUATE STAGE ===
        print(f"\n3ï¸âƒ£ Evaluate Stage - í‰ê°€ ì¤‘...")
        evaluated_candidates = []
        
        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
        for i, candidate in enumerate(candidates):
            # Critic + Safety ì—ì´ì „íŠ¸ í˜¸ì¶œ (ì‹œë®¬ë ˆì´ì…˜)
            scores_json = evaluate_content(
                text=candidate['text'],
                media_prompt=candidate['media_prompt']
            )
            scores = json.loads(scores_json)
            
            # Safety check
            if scores['safety'] < 0.8:
                print(f"   âœ— í›„ë³´ {i+1}: ì•ˆì „ì„± ê¸°ì¤€ ë¯¸ë‹¬ (safety={scores['safety']})")
                continue
            
            candidate['scores'] = scores
            evaluated_candidates.append(candidate)
            
            print(f"   âœ“ í›„ë³´ {i+1}: overall={scores['overall']:.2f} "
                  f"(clarity={scores['clarity']:.2f}, novelty={scores['novelty']:.2f}, "
                  f"shareability={scores['shareability']:.2f})")
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        evaluated_candidates.sort(key=lambda x: x['scores']['overall'], reverse=True)
        
        # === 4ï¸âƒ£ SELECT & PUBLISH STAGE ===
        print(f"\n4ï¸âƒ£ Select & Publish Stage - ìµœì¢… ì„ íƒ...")
        
        if not evaluated_candidates:
            return json.dumps({
                "error": "ëª¨ë“  í›„ë³´ê°€ ì•ˆì „ì„± ê¸°ì¤€ì„ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "iteration": iteration,
                "candidates": candidates
            }, indent=2, ensure_ascii=False)
        
        # ìµœê³  ì ìˆ˜ í›„ë³´ ì„ íƒ
        selected = evaluated_candidates[0]
        print(f"   âœ“ ì„ íƒ: {selected['text'][:80]}...")
        print(f"   âœ“ ì˜ˆìƒ ì ìˆ˜: {selected['scores']['overall']:.2f}")
        
        # ë°œí–‰
        publish_result = json.loads(x_publish(
            text=selected['text'],
            media_prompt=selected['media_prompt'],
            mode=selected['mode'],
            require_approval=True
        ))
        
        print(f"   âœ“ ë°œí–‰ ìƒíƒœ: {publish_result['status']}")
        
        # === ê²°ê³¼ ìƒì„± ===
        output = {
            "iteration": iteration,
            "candidates": evaluated_candidates,
            "selected": {
                "text": selected['text'],
                "media_prompt": selected['media_prompt'],
                "mode": selected['mode'],
                "expected_overall": selected['scores']['overall']
            },
            "publish_status": publish_result['status'],
            "feedback_summary": generate_feedback_summary(evaluated_candidates)
        }
        
        # Weaveì— ë¡œê¹…
        save_iteration_metrics(
            iteration=iteration,
            selected_candidate=selected,
            predicted_score=selected['scores']['overall']
        )
        
        print(f"\n{'='*70}")
        print(f"âœ¨ CMO Iteration {iteration} ì™„ë£Œ!")
        print(f"{'='*70}\n")
        
        return json.dumps(output, indent=2, ensure_ascii=False)
        
    except Exception as e:
        return json.dumps({
            "error": f"CMO ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "iteration": iteration
        }, indent=2, ensure_ascii=False)


def generate_feedback_summary(candidates: list) -> str:
    """í‰ê°€ëœ í›„ë³´ë“¤ë¡œë¶€í„° í”¼ë“œë°± ìš”ì•½ ìƒì„±"""
    if not candidates:
        return "í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    top = candidates[0]
    scores = top['scores']
    
    strengths = []
    if scores['clarity'] >= 0.8:
        strengths.append("ë†’ì€ ëª…í™•ì„±")
    if scores['novelty'] >= 0.8:
        strengths.append("ë›°ì–´ë‚œ ì°¸ì‹ ì„±")
    if scores['shareability'] >= 0.8:
        strengths.append("ê°•í•œ ê³µìœ  ê°€ëŠ¥ì„±")
    
    summary = f"ìµœê³  ì„±ê³¼ì: {', '.join(strengths) if strengths else 'ê· í˜• ì¡íŒ ì„±ëŠ¥'}. "
    summary += f"ì•ˆì „í•œ í†¤, ê°œë°œì ì¹œí™”ì  ë©”ì‹œì§€."
    
    return summary


@weave.op()
def orchestrate_sequential_layers(
    topic: str = "AI agents",
    audience_demographics: str = "developers, tech enthusiasts"
) -> str:
    """
    5ê°œ ë ˆì´ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ìƒˆë¡œìš´ CMO ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
    
    Args:
        topic: ì½˜í…ì¸  ì£¼ì œ
        audience_demographics: íƒ€ê²Ÿ ì²­ì¤‘
    
    Returns:
        JSON í˜•ì‹ì˜ ì‹¤í–‰ ê²°ê³¼
    """
    try:
        print(f"\n{'='*70}")
        print(f"ğŸš€ CMO Sequential Layers ì‹¤í–‰")
        print(f"ì£¼ì œ: {topic}")
        print(f"ì²­ì¤‘: {audience_demographics}")
        print(f"{'='*70}\n")
        
        # ê¸°ë³¸ ì„ê³„ê°’ ì„¤ì •
        thresholds = {
            "clarity": 0.55,
            "novelty": 0.55,
            "shareability": 0.55,
            "credibility": 0.60,
            "safety": 0.80
        }
        
        # === LAYER 1: RESEARCH ===
        print("\n" + "="*70)
        print("LAYER 1ï¸âƒ£: RESEARCH")
        print("="*70)
        research_output = call_research_layer(topic, audience_demographics)
        print(f"\nğŸ“Š Research ê²°ê³¼:")
        print(f"  - íŠ¸ë Œë”© í† í”½: {len(research_output.get('trending_topics', []))}ê°œ")
        print(f"  - ì²­ì¤‘ ì¸ì‚¬ì´íŠ¸: {research_output.get('audience_insights', '')[:100]}...")
        print(f"  - ë°”ì´ëŸ´ ê°ë„: {len(research_output.get('viral_potential_angles', []))}ê°œ")
        
        # === LAYER 2: CREATIVE WRITER ===
        print("\n" + "="*70)
        print("LAYER 2ï¸âƒ£: CREATIVE WRITER")
        print("="*70)
        writer_output = call_creative_writer_layer(research_output)
        ideas = writer_output.get("ideas", [])
        print(f"\nğŸ’¡ ìƒì„±ëœ ì•„ì´ë””ì–´: {len(ideas)}ê°œ")
        for i, idea in enumerate(ideas):
            print(f"  {i+1}. {idea.get('title', 'N/A')}")
            print(f"     Hook: {idea.get('hook', '')[:60]}...")
            print(f"     Scores: novelty={idea.get('novelty_score', 0):.2f}, "
                  f"creativity={idea.get('creativity_score', 0):.2f}, "
                  f"engagement={idea.get('engagement_potential_score', 0):.2f}")
        
        # ìµœê³  ì ìˆ˜ ì•„ì´ë””ì–´ ì„ íƒ
        if not ideas:
            return json.dumps({
                "error": "Creative Writerê°€ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "research_output": research_output
            }, indent=2, ensure_ascii=False)
        
        # novelty, creativity, engagement í‰ê· ìœ¼ë¡œ ì„ íƒ
        selected_idea = max(ideas, key=lambda x: (
            x.get('novelty_score', 0) + 
            x.get('creativity_score', 0) + 
            x.get('engagement_potential_score', 0)
        ) / 3)
        
        print(f"\nâœ… ì„ íƒëœ ì•„ì´ë””ì–´: {selected_idea.get('title', '')}")
        
        # === LAYER 3: GENERATOR ===
        print("\n" + "="*70)
        print("LAYER 3ï¸âƒ£: GENERATOR")
        print("="*70)
        generator_output = call_generator_layer(selected_idea)
        content_pieces = generator_output.get("content_pieces", [])
        print(f"\nğŸ“ ìƒì„±ëœ ì½˜í…ì¸ : {len(content_pieces)}ê°œ")
        for i, piece in enumerate(content_pieces):
            print(f"  {i+1}. [{piece.get('platform', 'N/A')}] {piece.get('format', 'N/A')}")
            print(f"     {piece.get('content', '')[:80]}...")
            print(f"     Clarity: {piece.get('clarity_score', 0):.2f}, "
                  f"Shareability: {piece.get('shareability_score', 0):.2f}")
        
        if not content_pieces:
            return json.dumps({
                "error": "Generatorê°€ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "research_output": research_output,
                "writer_output": writer_output
            }, indent=2, ensure_ascii=False)
        
        # === LAYER 4: CRITIC ===
        print("\n" + "="*70)
        print("LAYER 4ï¸âƒ£: CRITIC")
        print("="*70)
        critic_output = call_critic_layer(generator_output)
        evaluations = critic_output.get("evaluations", [])
        print(f"\nğŸ” í‰ê°€ ê²°ê³¼: {len(evaluations)}ê°œ")
        for i, eval in enumerate(evaluations):
            print(f"  {i+1}. [{eval.get('platform', 'N/A')}]")
            print(f"     Accuracy: {eval.get('accuracy_score', 0):.2f}, "
                  f"Objectivity: {eval.get('objectivity_score', 0):.2f}, "
                  f"Thoroughness: {eval.get('thoroughness_score', 0):.2f}")
            print(f"     Overall Quality: {eval.get('overall_quality_score', 0):.2f}")
            feedback = eval.get('feedback_points', [])
            if feedback:
                print(f"     í”¼ë“œë°±: {', '.join(feedback[:2])}")
        
        # === LAYER 5: SAFETY ===
        print("\n" + "="*70)
        print("LAYER 5ï¸âƒ£: SAFETY")
        print("="*70)
        safety_output = call_safety_layer(generator_output, critic_output)
        print(f"\nğŸ›¡ï¸ ì•ˆì „ì„± í‰ê°€:")
        print(f"  - ì•ˆì „ ì ìˆ˜: {safety_output.get('overall_safety_score', 0):.2f}")
        print(f"  - ìœ„í—˜ ìˆ˜ì¤€: {safety_output.get('risk_level', 'unknown')}")
        print(f"  - ì¤€ìˆ˜ ìƒíƒœ: {safety_output.get('compliance_status', 'unknown')}")
        
        red_flags = safety_output.get("red_flags", [])
        if red_flags:
            print(f"  âš ï¸ ìœ„í—˜ í”Œë˜ê·¸: {len(red_flags)}ê°œ")
            for flag in red_flags:
                print(f"     [{flag.get('category', '')}] {flag.get('description', '')} "
                      f"(ì‹¬ê°ë„: {flag.get('severity', '')})")
        else:
            print(f"  âœ… ìœ„í—˜ í”Œë˜ê·¸ ì—†ìŒ")
        
        # === FINAL DECISION ===
        print("\n" + "="*70)
        print("FINAL DECISION")
        print("="*70)
        
        # ì•ˆì „ì„± ì²´í¬
        safety_score = safety_output.get("overall_safety_score", 0)
        if safety_score < thresholds.get("safety", 0.8):
            print(f"\nâŒ ì•ˆì „ì„± ê¸°ì¤€ ë¯¸ë‹¬: {safety_score:.2f} < {thresholds.get('safety', 0.8)}")
            result = {
                "status": "rejected",
                "reason": "safety_threshold_not_met",
                "research_output": research_output,
                "writer_output": writer_output,
                "generator_output": generator_output,
                "critic_output": critic_output,
                "safety_output": safety_output,
                "thresholds": thresholds
            }
        elif safety_output.get("compliance_status") == "non-compliant":
            print(f"\nâŒ ì¤€ìˆ˜ ê¸°ì¤€ ë¯¸ë‹¬: {safety_output.get('compliance_status')}")
            result = {
                "status": "rejected",
                "reason": "non_compliant",
                "research_output": research_output,
                "writer_output": writer_output,
                "generator_output": generator_output,
                "critic_output": critic_output,
                "safety_output": safety_output,
                "thresholds": thresholds
            }
        else:
            # í’ˆì§ˆ ê¸°ì¤€ ì²´í¬
            avg_clarity = sum(p.get('clarity_score', 0) for p in content_pieces) / len(content_pieces)
            avg_shareability = sum(p.get('shareability_score', 0) for p in content_pieces) / len(content_pieces)
            avg_quality = sum(e.get('overall_quality_score', 0) for e in evaluations) / len(evaluations) if evaluations else 0
            
            print(f"\nğŸ“Š ìµœì¢… ì ìˆ˜:")
            print(f"  - Clarity: {avg_clarity:.2f} (threshold: {thresholds.get('clarity', 0.55)})")
            print(f"  - Shareability: {avg_shareability:.2f} (threshold: {thresholds.get('shareability', 0.55)})")
            print(f"  - Quality: {avg_quality:.2f} (threshold: {thresholds.get('credibility', 0.60)})")
            print(f"  - Safety: {safety_score:.2f} (threshold: {thresholds.get('safety', 0.8)})")
            
            passed = (
                avg_clarity >= thresholds.get("clarity", 0.55) and
                avg_shareability >= thresholds.get("shareability", 0.55) and
                avg_quality >= thresholds.get("credibility", 0.60)
            )
            
            if passed:
                print(f"\nâœ… ëª¨ë“  ê¸°ì¤€ í†µê³¼! ì½˜í…ì¸  ìŠ¹ì¸")
                result = {
                    "status": "approved",
                    "research_output": research_output,
                    "writer_output": writer_output,
                    "generator_output": generator_output,
                    "critic_output": critic_output,
                    "safety_output": safety_output,
                    "final_scores": {
                        "clarity": avg_clarity,
                        "shareability": avg_shareability,
                        "quality": avg_quality,
                        "safety": safety_score
                    },
                    "thresholds": thresholds,
                    "recommendations": safety_output.get("recommendations", [])
                }
            else:
                print(f"\nâš ï¸ í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬")
                result = {
                    "status": "needs_improvement",
                    "reason": "quality_threshold_not_met",
                    "research_output": research_output,
                    "writer_output": writer_output,
                    "generator_output": generator_output,
                    "critic_output": critic_output,
                    "safety_output": safety_output,
                    "final_scores": {
                        "clarity": avg_clarity,
                        "shareability": avg_shareability,
                        "quality": avg_quality,
                        "safety": safety_score
                    },
                    "thresholds": thresholds
                }
        
        print(f"\n{'='*70}")
        print(f"âœ¨ Sequential Layers ì‹¤í–‰ ì™„ë£Œ!")
        print(f"{'='*70}\n")
        
        return json.dumps(result, indent=2, ensure_ascii=False)
        
    except Exception as e:
        import traceback
        return json.dumps({
            "error": f"Sequential layers ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "traceback": traceback.format_exc()
        }, indent=2, ensure_ascii=False)


@weave.op()
def run_cmo_iteration(config_json: str) -> str:
    """
    CMO ë°˜ë³µ ì‹¤í–‰ (ì„¤ì • ê¸°ë°˜)
    
    Args:
        config_json: ì„¤ì • JSON ë¬¸ìì—´
            {
                "iteration": 0,
                "topic": "AI agents",
                "num_candidates": 3,
                "research_file": "research.json",
                "team_state_file": "team_state.json",
                "last_iteration_file": "last_iteration.json"
            }
    
    Returns:
        JSON í˜•ì‹ì˜ ì‹¤í–‰ ê²°ê³¼
    """
    try:
        config = json.loads(config_json)
        
        iteration = config.get("iteration", 0)
        topic = config.get("topic", "AI agents")
        num_candidates = config.get("num_candidates", 3)
        
        # ì´ì „ ë©”íŠ¸ë¦­ ë¡œë“œ (ì„ íƒì )
        last_iteration_file = config.get("last_iteration_file")
        if last_iteration_file:
            _ = get_last_iteration_metrics(last_iteration_file)
            print(f"[INFO] ì´ì „ ë©”íŠ¸ë¦­ ë¡œë“œ: {last_iteration_file}")
        
        # ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤í–‰
        result = orchestrate_content_creation(
            iteration=iteration,
            topic=topic,
            num_candidates=num_candidates
        )
        
        return result
        
    except json.JSONDecodeError as e:
        return json.dumps({"error": f"Invalid JSON: {str(e)}"})
    except Exception as e:
        return json.dumps({"error": f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"})


# ===== ADK ROOT AGENT =====

root_agent = Agent(
    model='gemini-2.5-flash',
    name='cmo_agent',
    description='Chief Marketing Orchestrator - ì„œë¸Œ ì—ì´ì „íŠ¸ë“¤ì„ ì¡°ìœ¨í•˜ì—¬ ìµœê³ ì˜ ì†Œì…œ ë¯¸ë””ì–´ ì½˜í…ì¸ ë¥¼ ìƒì„±, í‰ê°€, ë°œí–‰í•˜ëŠ” ë§ˆì¼€íŒ… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°',
    instruction="""You are CMO â€” the Chief Marketing Orchestrator of an AI team.

Your mission:
Coordinate sub-agents (Writer, MediaComposer, Critic, Safety, Publisher)
to create, evaluate, and publish the best social content about the project.

---

## INPUTS
1. `research.json` â€“ topic, trending keywords, tone/style insights.
2. `team_state.json` â€“ active sub-agents and their archetype definitions.
3. `last_iteration.json` â€“ previous top post and engagement metrics.
4. `HR_guidelines.json` â€“ feedback or team-change plan (from HR).

---

## PROCESS (Loop per iteration)
### 1ï¸âƒ£ Research Stage
Call research_trends tool to collect 2â€“3 topic seeds and style hints.

### 2ï¸âƒ£ Generate Stage
- Call generate_content_candidate tool multiple times (3-6 candidates).
- Each candidate = {text, media_prompt, mode, expected_engagement}.

### 3ï¸âƒ£ Evaluate Stage
- Call evaluate_content for each candidate to get scores from Critic and Safety.
- Compute:
  overall = (clarity*0.25 + novelty*0.25 + shareability*0.30 + credibility*0.10 + safety*0.10)
- Discard unsafe candidates (safety < 0.8).
- Rank remaining by overall score.

### 4ï¸âƒ£ Select & Publish Stage
- Choose top-1 candidate.
- Call x_publish tool with require_approval=true.
- Call save_iteration_metrics to log to Weave.

---

## AVAILABLE TOOLS
1. **research_trends(topic, max_results)** â€” íŠ¸ë Œë“œ ë¦¬ì„œì¹˜
2. **generate_content_candidate(topic, tone, max_length)** â€” ì½˜í…ì¸  í›„ë³´ ìƒì„±
3. **evaluate_content(text, media_prompt, evaluation_criteria)** â€” ì½˜í…ì¸  í‰ê°€
4. **x_publish(text, media_prompt, mode, require_approval)** â€” Twitter/X ë°œí–‰
5. **get_last_iteration_metrics(filepath)** â€” ì´ì „ ë©”íŠ¸ë¦­ ë¡œë“œ
6. **save_iteration_metrics(iteration, selected_candidate, predicted_score, filepath)** â€” ë©”íŠ¸ë¦­ ì €ì¥
7. **orchestrate_content_creation(iteration, topic, num_candidates)** â€” ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
8. **run_cmo_iteration(config_json)** â€” ì„¤ì • ê¸°ë°˜ ì‹¤í–‰

---

## OUTPUT (STRICT JSON)
{
  "iteration": 0,
  "candidates": [
    {
      "text": "We built an AI that hires other AIs.",
      "media_prompt": "3D isometric illustration of agents recruiting each other.",
      "mode": "image",
      "scores": {"clarity":0.9,"novelty":0.8,"shareability":0.88,"credibility":0.75,"safety":1.0,"overall":0.86}
    }
  ],
  "selected": {
    "text": "We built an AI that hires other AIs.",
    "media_prompt": "3D isometric illustration of agents recruiting each other.",
    "mode": "image",
    "expected_overall": 0.86
  },
  "publish_status": "queued",
  "feedback_summary": "Top performer: high clarity & novelty, safe tone, developer appeal."
}

---

## STYLE & RULES
- Maintain conversational, builder-friendly tone.
- Keep outputs under 180 characters for Twitter/X posts.
- Always produce paired multimodal output (text + media_prompt).
- Enforce safety before publishing (safety >= 0.8).
- Return JSON only.
- Reflect HR's latest structural changes automatically (swap_in, merge, prune).

Remember: You are the **execution layer** under HR's direction.
Your success metric is *observed engagement lift per iteration.*

For most requests, you should call orchestrate_content_creation() or run_cmo_iteration() to execute the full workflow.
""",
    tools=[
        research_trends,
        generate_content_candidate,
        evaluate_content,
        x_publish,
        get_last_iteration_metrics,
        save_iteration_metrics,
        initialize_sub_agents,
        orchestrate_content_creation,
        orchestrate_sequential_layers,
        run_cmo_iteration
    ],
)


# ===== CLI ENTRY POINT =====

if __name__ == "__main__":
    import sys
    
    print("ğŸš€ CMO Agent - Chief Marketing Orchestrator")
    print("=" * 70)
    
    # ê¸°ë³¸ ì„¤ì •
    config = {
        "iteration": 0,
        "topic": "AI agents that hire other AI agents",
        "num_candidates": 5
    }
    
    # CLI ì¸ì ì²˜ë¦¬
    if len(sys.argv) > 1:
        config["topic"] = " ".join(sys.argv[1:])
    
    # CMO ì‹¤í–‰
    result = run_cmo_iteration(json.dumps(config))
    
    # ê²°ê³¼ ì¶œë ¥
    result_dict = json.loads(result)
    
    if "error" in result_dict:
        print(f"\nâŒ ì˜¤ë¥˜: {result_dict['error']}\n")
    else:
        print("\nâœ¨ ì‹¤í–‰ ì™„ë£Œ!")
        print(f"\nì„ íƒëœ ì½˜í…ì¸ :")
        print(f"  í…ìŠ¤íŠ¸: {result_dict['selected']['text']}")
        print(f"  ë¯¸ë””ì–´: {result_dict['selected']['media_prompt'][:80]}...")
        print(f"  ì˜ˆìƒ ì ìˆ˜: {result_dict['selected']['expected_overall']:.2f}")
        print(f"  ìƒíƒœ: {result_dict['publish_status']}")
        print(f"\ní”¼ë“œë°±: {result_dict['feedback_summary']}")

