"""
CMO Agent ë„êµ¬ í•¨ìˆ˜ë“¤
"""

import json
import random
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import weave
from cmo_agent.schemas import ContentCandidate, EvaluationScores


def load_latest_trend_data() -> Optional[Dict[str, Any]]:
    """
    Load the most recent trending data from trend_data/ directory.

    Returns:
        Dict with trend data or None if no data found
    """
    trend_data_dir = Path(__file__).parent.parent / "trend_data"

    if not trend_data_dir.exists():
        print("âš ï¸ trend_data/ directory not found")
        return None

    # Find most recent trending_*.json file
    trend_files = sorted(trend_data_dir.glob("trending_*.json"), reverse=True)

    if not trend_files:
        print("âš ï¸ No trend data files found in trend_data/")
        return None

    latest_file = trend_files[0]
    print(f"ğŸ“Š Loading trend data from: {latest_file.name}")

    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ Error loading trend data: {e}")
        return None


@weave.op()
def research_trends(topic: str = "AI agents", max_results: int = 10) -> str:
    """
    íŠ¸ë Œë“œ ë¦¬ì„œì¹˜ ìˆ˜í–‰ - Load real trending data from trend_data/ directory

    Args:
        topic: ì¡°ì‚¬í•  ì£¼ì œ (optional filter, ignored if real data available)
        max_results: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜

    Returns:
        JSON í˜•ì‹ì˜ ë¦¬ì„œì¹˜ ê²°ê³¼ with trending_topics array
    """
    # Load real trending data
    trend_data = load_latest_trend_data()

    if trend_data:
        # Extract trending topics from the pipeline output
        trending_topics = []

        # Get data from data_sources structure
        data_sources = trend_data.get("data_sources", {})

        # Extract from twitter_trends if available
        if "twitter_trends" in data_sources:
            twitter_trends = data_sources["twitter_trends"]
            if twitter_trends.get("collected"):
                tabs_data = twitter_trends.get("data", {}).get("tabs", {})

                for category, tab_info in tabs_data.items():
                    topics_list = tab_info.get("trending_topics", [])
                    for topic in topics_list[:max_results]:
                        trending_topics.append({
                            "topic_name": topic.get("topic_name", "Unknown"),
                            "source": f"Twitter/{category}",
                            "rank": topic.get("rank", "N/A"),
                            "url": topic.get("url", ""),
                            "engagement_hint": topic.get("engagement_hint", "unknown"),
                            "raw_text": topic.get("raw_text", "")[:200]
                        })

        # Extract from post_analysis if available
        if "post_analysis" in data_sources:
            post_analysis_data = data_sources["post_analysis"]
            if post_analysis_data.get("collected"):
                analysis_data = post_analysis_data.get("data", {})
                for keyword_data in analysis_data.get("keywords", [])[:max_results]:
                    keyword = keyword_data.get("keyword", "")
                    posts = keyword_data.get("posts", [])

                    if posts:
                        # Get the most engaging post
                        top_post = posts[0] if posts else {}
                        trending_topics.append({
                            "topic_name": keyword,
                            "source": "Post Analysis",
                            "post_count": len(posts),
                            "top_post": {
                                "title": top_post.get("title", ""),
                                "url": top_post.get("url", ""),
                                "content": top_post.get("content", "")[:200]
                            }
                        })

        # Limit to max_results
        trending_topics = trending_topics[:max_results]

        result = {
            "status": "success",
            "source": "real_trend_data",
            "timestamp": trend_data.get("timestamp", ""),
            "trending_topics": trending_topics,
            "total_topics": len(trending_topics),
            "insights": f"Loaded {len(trending_topics)} trending topics from real-time data collection"
        }

        print(f"âœ… Loaded {len(trending_topics)} real trending topics")
        return json.dumps(result, indent=2, ensure_ascii=False)

    else:
        # Fallback to mock data if no real data available
        print("âš ï¸ No real trend data available, using fallback")

        trending_keywords = [
            "AI", "agents", "automation", "LLM", "GPT", "Claude",
            "developers", "builders", "indie hackers", "startups"
        ]

        sample_topics = [
            f"{topic}ì™€ ìë™í™”ì˜ ë¯¸ë˜",
            f"{topic} ê°œë°œì ê²½í—˜ ê°œì„ ",
            f"{topic}ê°€ ë°”ê¾¸ëŠ” ì›Œí¬í”Œë¡œìš°"
        ]

        result = {
            "status": "fallback",
            "source": "mock_data",
            "topics": random.sample(sample_topics, min(max_results, len(sample_topics))),
            "keywords": random.sample(trending_keywords, min(5, len(trending_keywords))),
            "tone_style": "conversational, builder-friendly",
            "insights": f"{topic}ì— ëŒ€í•œ ê°œë°œìë“¤ì˜ ê´€ì‹¬ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤."
        }

        return json.dumps(result, indent=2, ensure_ascii=False)


@weave.op()
def generate_content_candidate(
    topic: str,
    tone: str = "conversational",
    max_length: int = 180
) -> str:
    """
    ì½˜í…ì¸  í›„ë³´ ìƒì„± (Writer ì—ì´ì „íŠ¸ ì‹œë®¬ë ˆì´ì…˜)
    
    Args:
        topic: ì½˜í…ì¸  ì£¼ì œ
        tone: í†¤/ìŠ¤íƒ€ì¼
        max_length: ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´
    
    Returns:
        JSON í˜•ì‹ì˜ ì½˜í…ì¸  í›„ë³´
    """
    
    # ì‹¤ì œë¡œëŠ” ViralCopywriter, Hooksmith ë“± ì„œë¸Œ ì—ì´ì „íŠ¸ í˜¸ì¶œ
    # ì—¬ê¸°ì„œëŠ” í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„±
    
    hooks = [
        f"ìš°ë¦¬ëŠ” {topic}ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.",
        f"{topic}ë¡œ íŒ€ì„ ìë™í™”í•˜ëŠ” ë°©ë²•",
        f"ì™œ ëª¨ë“  ê°œë°œìê°€ {topic}ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ê°€",
        f"{topic}ì˜ ë¯¸ë˜ëŠ” ì´ë¯¸ ì—¬ê¸°ì— ìˆìŠµë‹ˆë‹¤",
    ]
    
    text = random.choice(hooks)
    
    candidate = {
        "text": text[:max_length],
        "media_prompt": f"3D isometric illustration of {topic}, modern tech aesthetic, vibrant colors",
        "mode": random.choice(["image", "image", "gif"]),  # image í™•ë¥  ë†’ê²Œ
        "expected_engagement": round(random.uniform(0.6, 0.9), 2)
    }
    
    return json.dumps(candidate, indent=2, ensure_ascii=False)


@weave.op()
def evaluate_content(
    text: str,
    media_prompt: str
) -> str:
    """
    ì½˜í…ì¸  í‰ê°€ (Critic + Safety ì—ì´ì „íŠ¸ ì‹œë®¬ë ˆì´ì…˜)
    
    Args:
        text: í‰ê°€í•  í…ìŠ¤íŠ¸
        media_prompt: ë¯¸ë””ì–´ í”„ë¡¬í”„íŠ¸
    
    Returns:
        JSON í˜•ì‹ì˜ í‰ê°€ ì ìˆ˜
    """
    
    # ì‹¤ì œë¡œëŠ” Critic, Safety ì—ì´ì „íŠ¸ë¥¼ ë³‘ë ¬ë¡œ í˜¸ì¶œ
    # ì—¬ê¸°ì„œëŠ” ê·œì¹™ ê¸°ë°˜ + ëœë¤ ì ìˆ˜
    
    # ê¸°ë³¸ ì ìˆ˜ (0.5~0.9 ì‚¬ì´)
    base_score = 0.7
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ clarity ì¡°ì •
    clarity = base_score + (0.2 if len(text) < 200 else 0.0)
    clarity = min(clarity, 1.0)
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ novelty
    novelty_keywords = ["AI", "agents", "automation", "future"]
    novelty = base_score + (0.1 if any(kw.lower() in text.lower() for kw in novelty_keywords) else 0.0)
    
    # shareabilityëŠ” ì§§ê³  ì„íŒ©íŠ¸ ìˆìœ¼ë©´ ë†’ìŒ
    shareability = base_score + (0.15 if len(text) < 150 else 0.0)
    shareability = min(shareability, 1.0)
    
    # credibilityëŠ” ëŒ€ë¶€ë¶„ ì–‘í˜¸
    credibility = 0.75 + random.uniform(0, 0.15)
    
    # safetyëŠ” ê±°ì˜ í•­ìƒ ë†’ìŒ (ë¬¸ì œ ìˆëŠ” ì½˜í…ì¸ ëŠ” ì‚¬ì „ í•„í„°ë§)
    safety = 0.95 + random.uniform(0, 0.05)
    
    scores = EvaluationScores(
        clarity=round(clarity, 2),
        novelty=round(novelty, 2),
        shareability=round(shareability, 2),
        credibility=round(credibility, 2),
        safety=round(safety, 2),
        overall=0.0  # ë‚˜ì¤‘ì— ê³„ì‚°
    )
    
    # overall ê³„ì‚°
    weights = {
        "clarity": 0.25,
        "novelty": 0.25,
        "shareability": 0.30,
        "credibility": 0.10,
        "safety": 0.10
    }
    
    overall = sum(
        getattr(scores, metric) * weight 
        for metric, weight in weights.items()
    )
    scores.overall = round(overall, 2)
    
    return scores.model_dump_json(indent=2)


@weave.op()
def x_publish(
    text: str,
    media_prompt: str,
    mode: str = "image",
    require_approval: bool = True
) -> str:
    """
    Twitter/Xì— ë°œí–‰
    
    Args:
        text: í¬ìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        media_prompt: ë¯¸ë””ì–´ ìƒì„± í”„ë¡¬í”„íŠ¸
        mode: ë¯¸ë””ì–´ íƒ€ì…
        require_approval: ìŠ¹ì¸ í•„ìš” ì—¬ë¶€
    
    Returns:
        JSON í˜•ì‹ì˜ ë°œí–‰ ìƒíƒœ
    """
    
    # ì‹¤ì œë¡œëŠ” Twitter API í˜¸ì¶œ
    # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    
    status = "queued" if require_approval else "published"
    
    result = {
        "status": status,
        "post_id": f"sim_{datetime.now().timestamp()}",
        "text": text,
        "media_prompt": media_prompt,
        "mode": mode,
        "scheduled_time": datetime.now().isoformat(),
        "requires_approval": require_approval,
        "message": "ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤." if require_approval else "ë°œí–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
    }
    
    return json.dumps(result, indent=2, ensure_ascii=False)


@weave.op()
def get_last_iteration_metrics(filepath: str = "last_iteration.json") -> str:
    """
    ì´ì „ ë°˜ë³µì˜ ë©”íŠ¸ë¦­ ë¡œë“œ
    
    Args:
        filepath: ë©”íŠ¸ë¦­ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        JSON í˜•ì‹ì˜ ë©”íŠ¸ë¦­
    """
    try:
        import os
        if os.path.exists(filepath):
            with open(filepath, 'r') as f:
                return f.read()
        else:
            return json.dumps({
                "iteration": 0,
                "top_post": None,
                "engagement": {"likes": 0, "reposts": 0, "comments": 0}
            }, indent=2)
    except Exception as e:
        return json.dumps({"error": str(e)})


@weave.op()
def save_iteration_metrics(
    iteration: int,
    selected_candidate: Dict[str, Any],
    predicted_score: float,
    filepath: str = "last_iteration.json"
) -> str:
    """
    í˜„ì¬ ë°˜ë³µ ë©”íŠ¸ë¦­ ì €ì¥
    
    Args:
        iteration: ë°˜ë³µ ë²ˆí˜¸
        selected_candidate: ì„ íƒëœ í›„ë³´
        predicted_score: ì˜ˆìƒ ì ìˆ˜
        filepath: ì €ì¥ ê²½ë¡œ
    
    Returns:
        ì €ì¥ ìƒíƒœ ë©”ì‹œì§€
    """
    try:
        data = {
            "iteration": iteration,
            "timestamp": datetime.now().isoformat(),
            "selected_candidate": selected_candidate,
            "predicted_score": predicted_score,
            "engagement": {"likes": 0, "reposts": 0, "comments": 0}  # ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
        }
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        return json.dumps({"status": "success", "message": f"ë©”íŠ¸ë¦­ì´ {filepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."})
    except Exception as e:
        return json.dumps({"status": "error", "message": str(e)})

