"""
í•©ì˜ ê¸°ë°˜ ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ
"""

from typing import Dict, Tuple, Optional, Any
import json
import weave


class ContentGenerator:
    """
    Multi-turn refinement with consensus.
    ì—ì´ì „íŠ¸ë“¤ì´ í’ˆì§ˆ ê¸°ì¤€ì„ ë§Œì¡±í•  ë•Œê¹Œì§€ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ .
    """
    
    def __init__(self, agents: Dict[str, Any], config: Dict = None):
        """
        Args:
            agents: {name: Agent} ë”•ì…”ë„ˆë¦¬
            config: {
                "max_iterations": 5,
                "min_quality_score": 0.75,
                "min_safety_score": 0.9
            }
        """
        self.agents = agents
        self.config = config or {
            "max_iterations": 5,
            "min_quality_score": 0.75,
            "min_safety_score": 0.9
        }
    
    @weave.op()
    def generate(self, topic: str, verbose: bool = True) -> Tuple[Optional[str], int, Dict]:
        """
        í•©ì˜ ê¸°ë°˜ ì½˜í…ì¸  ìƒì„±.
        
        Args:
            topic: ì½˜í…ì¸  ì£¼ì œ
            verbose: ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            (content, iterations, scores)
            - content: ìµœì¢… ì½˜í…ì¸  (or None if failed)
            - iterations: ê±¸ë¦° ë¼ìš´ë“œ ìˆ˜
            - scores: ìµœì¢… ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
        """
        if verbose:
            print(f"\nğŸ¨ ì½˜í…ì¸  ìƒì„± ì‹œì‘: {topic}")
            print("=" * 70)
        
        # Phase 1: Research & Context Gathering
        context = self._gather_context(topic, verbose)
        
        # Phase 2: Iterative Refinement
        content = None
        scores = None
        
        for i in range(1, self.config["max_iterations"] + 1):
            if verbose:
                print(f"\n{'='*70}")
                print(f"Round {i}/{self.config['max_iterations']}")
                print(f"{'='*70}")
            
            # Write/Revise
            content = self._write_content(content, context, scores, iteration=i, verbose=verbose)
            
            if verbose:
                print(f"\nğŸ“ Content ({len(content)} chars):")
                print(content[:200] + "..." if len(content) > 200 else content)
            
            # Evaluate
            scores = self._evaluate_content(content, verbose)
            
            if verbose:
                print(f"\nğŸ“Š Scores:")
                for key, val in scores.items():
                    if key != "feedback":
                        print(f"  {key}: {val:.2f}")
            
            # Check consensus
            if self._is_consensus_reached(scores):
                if verbose:
                    print(f"\nâœ… Consensus reached after {i} rounds!")
                    print(f"Overall: {scores['overall']:.2f} >= {self.config['min_quality_score']}")
                return content, i, scores
            
            # Safety check
            if scores["safety"] < self.config["min_safety_score"]:
                if verbose:
                    print(f"\nâŒ Safety violation! Aborting.")
                return None, i, scores
            
            if verbose:
                print(f"\nâš ï¸  Quality: {scores['overall']:.2f} < {self.config['min_quality_score']}")
                print(f"Refining based on feedback...")
        
        # Max iterations reached
        if verbose:
            print(f"\nâ° Max iterations reached. Using best attempt.")
        return content, self.config["max_iterations"], scores
    
    @weave.op()
    def _gather_context(self, topic: str, verbose: bool) -> Dict:
        """Phase 1: ë³‘ë ¬ë¡œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        if verbose:
            print(f"\nğŸ” Phase 1: Gathering context...")
        
        context = {"topic": topic}
        
        # Analyzer agents (trends, ideas, etc.)
        if "TrendScout" in self.agents:
            if verbose:
                print("  - TrendScout analyzing trends...")
            # Mock response (ì‹¤ì œë¡œëŠ” agent.run() í˜¸ì¶œ)
            context["trends"] = {
                "top_topic": "AI agents trending",
                "sentiment": "positive",
                "engagement_potential": 0.85
            }
        
        if "Ideator" in self.agents:
            if verbose:
                print("  - Ideator brainstorming angles...")
            context["ideas"] = {
                "best_angle": "Behind-the-scenes of building agents",
                "alternatives": ["Contrarian take", "Tutorial", "Results showcase"]
            }
        
        return context
    
    @weave.op()
    def _write_content(
        self,
        previous_content: Optional[str],
        context: Dict,
        scores: Optional[Dict],
        iteration: int,
        verbose: bool
    ) -> str:
        """Phase 2: ì‘ì„± ë˜ëŠ” ìˆ˜ì •"""
        
        if iteration == 1:
            # ì²« ë²ˆì§¸: ì´ˆì•ˆ ì‘ì„±
            prompt = f"""Create a viral tweet about: {context['topic']}

Context:
- Trends: {json.dumps(context.get('trends', {}), indent=2)}
- Ideas: {json.dumps(context.get('ideas', {}), indent=2)}

Requirements:
- Attention-grabbing hook
- Specific examples
- Under 280 characters or thread format
- End with a call-to-action or cliffhanger"""
            
            # ğŸ¯ Weave Promptë¡œ publish (Round 1)
            try:
                prompt_obj = weave.StringPrompt(prompt)
                weave.publish(prompt_obj, name="content_generation_prompt")
                print(f"ğŸ“ Prompt published: Round {iteration} (Initial Draft)")
            except Exception as e:
                print(f"âš ï¸  Failed to publish prompt: {e}")
                import traceback
                traceback.print_exc()
            
            if verbose:
                print(f"\nâœï¸  Writers creating initial draft...")
        
        else:
            # ì´í›„: í”¼ë“œë°± ê¸°ë°˜ ìˆ˜ì •
            feedback_str = "\n".join(f"- {f}" for f in scores.get("feedback", []) if f)
            
            prompt = f"""Improve this content based on critic feedback:

Current Content:
{previous_content}

Feedback:
{feedback_str}

Current Score: {scores.get('overall', 0):.2f} / Target: {self.config['min_quality_score']}

Make specific improvements to raise the score."""
            
            # ğŸ¯ Weave Promptë¡œ publish (Round 2+)
            # ê°™ì€ ì´ë¦„ìœ¼ë¡œ publish â†’ ìë™ìœ¼ë¡œ ìƒˆ ë²„ì „ ìƒì„±!
            try:
                with weave.attributes({
                    'round': iteration,
                    'topic': context.get('topic', 'unknown'),
                    'previous_score': scores.get('overall', 0),
                    'target_score': self.config['min_quality_score'],
                    'improvement_stage': 'refinement'
                }):
                    prompt_obj = weave.StringPrompt(prompt)
                    weave.publish(prompt_obj, name="content_generation_prompt")
                    print(f"ğŸ“ Prompt published: Round {iteration} (Refinement, Score: {scores.get('overall', 0):.2f})")
            except Exception as e:
                print(f"âš ï¸  Failed to publish prompt: {e}")
                import traceback
                traceback.print_exc()
            
            if verbose:
                print(f"\nâœï¸  Writers refining (Round {iteration})...")
        
        # Writers ì‹¤í–‰
        writers = [name for name in self.agents.keys() if "writer" in self.agents[name].description.lower()]
        
        if writers:
            # ì‹¤ì œë¡œëŠ” agent.run(prompt) í˜¸ì¶œ
            # Mock response for demo
            if iteration == 1:
                content = """Everyone thinks building AI agents is hard. It's not.

I built a self-optimizing agent team for WeaveHack2.
The HR agent fires/hires other agents based on Twitter performance.

3 viral tweets later, here's what worked ğŸ‘‡

ğŸ§µ"""
            else:
                content = previous_content + "\n\n[Improved based on feedback]"
            
            return content
        
        return previous_content or "No writers available."
    
    @weave.op()
    def _evaluate_content(self, content: str, verbose: bool) -> Dict:
        """Phase 2: Criticsê°€ ë³‘ë ¬ í‰ê°€"""
        if verbose:
            print(f"\nğŸ” Critics evaluating...")
        
        scores = {
            "clarity": 0.5,
            "novelty": 0.5,
            "shareability": 0.5,
            "credibility": 0.5,
            "safety": 1.0,
            "feedback": []
        }
        
        # Mock evaluation (ì‹¤ì œë¡œëŠ” ê° critic agent ì‹¤í–‰)
        critics = [name for name in self.agents.keys() if "critic" in self.agents[name].description.lower()]
        
        if "ClarityChecker" in self.agents:
            scores["clarity"] = 0.85
            scores["feedback"].append("Good structure, clear message")
        
        if "EngageCritic" in self.agents:
            scores["novelty"] = 0.78
            scores["shareability"] = 0.82
            scores["credibility"] = 0.75
            scores["feedback"].append("Strong hook, needs more specifics")
        
        if "HRValidation" in self.agents:
            scores["safety"] = 1.0
        
        # Overall ê³„ì‚°
        scores["overall"] = (
            scores["clarity"] * 0.2 +
            scores["novelty"] * 0.2 +
            scores["shareability"] * 0.3 +
            scores["credibility"] * 0.2 +
            scores["safety"] * 0.1
        )
        
        return scores
    
    @weave.op()
    def _is_consensus_reached(self, scores: Dict) -> bool:
        """í•©ì˜ ë„ë‹¬ ì²´í¬"""
        return (
            scores["overall"] >= self.config["min_quality_score"] and
            scores["safety"] >= self.config["min_safety_score"]
        )


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    from agent_factory import apply_hr_decisions, load_team_state
    from hr_validation_agent.agent import analyze_team_and_decide
    import json
    
    print("ğŸš€ í•©ì˜ ê¸°ë°˜ ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # 1. ì—ì´ì „íŠ¸ íŒ€ ìƒì„±
    print("\n1ï¸âƒ£ HR Agentë¡œ ì´ˆê¸° íŒ€ ìƒì„±...")
    team_state = load_team_state("examples/mason_weavehack2_empty.json")
    result = analyze_team_and_decide(json.dumps(team_state))
    hr_decisions = json.loads(result)
    
    agents = {}
    agents = apply_hr_decisions(agents, hr_decisions, verbose=False)
    
    # 2. ì½˜í…ì¸  ìƒì„± (í•©ì˜ ê¸°ë°˜)
    print(f"\n2ï¸âƒ£ {len(agents)}ëª…ì˜ ì—ì´ì „íŠ¸ë¡œ ì½˜í…ì¸  ìƒì„±...")
    
    generator = ContentGenerator(agents, {
        "max_iterations": 3,  # Demoìš© 3íšŒ
        "min_quality_score": 0.75,
        "min_safety_score": 0.9
    })
    
    content, iterations, scores = generator.generate(
        topic="Building self-optimizing agents for WeaveHack2",
        verbose=True
    )
    
    print(f"\n{'='*70}")
    print("ğŸ“Š ìµœì¢… ê²°ê³¼")
    print(f"{'='*70}")
    print(f"âœ… Iterations: {iterations}")
    print(f"ğŸ“ˆ Final Score: {scores['overall']:.2f}")
    print(f"\nğŸ“ Final Content:")
    print(content)

